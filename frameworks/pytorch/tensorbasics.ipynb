{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8374aac2",
   "metadata": {},
   "source": [
    "# 1. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5daed76",
   "metadata": {},
   "source": [
    "A Tensor is a multi-dimensional matrix containing elements of a single data type.  \n",
    "*Everything in PyTorch is based on Tensor operations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70eb08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "574cef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(1): tensor([0.])\n",
      "\n",
      "empty(3): tensor([2.4435e-04, 9.2486e-43, 2.3694e-38])\n",
      "\n",
      "empty(2,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "empty(2, 2, 3): tensor([[[2.4992e-04, 9.2486e-43, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
      "\n",
      "rand(5,3): tensor([[0.7559, 0.6170, 0.1351],\n",
      "        [0.8258, 0.7403, 0.9201],\n",
      "        [0.6040, 0.5004, 0.8114],\n",
      "        [0.0159, 0.9595, 0.0955],\n",
      "        [0.4929, 0.5597, 0.7030]])\n",
      "\n",
      "zeros(5,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.empty(size): uninitiallized   \n",
    "# This creates a tensor without initializing the values. \n",
    "# That means the values in the tensor are just whatever was already in that block of memory (often garbage values).\n",
    "x = torch.empty(1) # scalar\n",
    "print(\"empty(1):\", x)\n",
    "\n",
    "x = torch.empty(3) # vector\n",
    "print(\"\\nempty(3):\",x)\n",
    "\n",
    "x = torch.empty(2, 3) # matrix\n",
    "print(\"\\nempty(2,3):\",x)\n",
    "\n",
    "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
    "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(\"\\nempty(2, 2, 3):\",x)\n",
    "\n",
    "# torch.rand(size): random numbers [0, 1] but more uniform\n",
    "x = torch.rand(5, 3)\n",
    "print(\"\\nrand(5,3):\", x)\n",
    "\n",
    "# torch.zeros(size), fill with 0\n",
    "# torch.ones(size), fill with 1\n",
    "x = torch.zeros(5, 3)\n",
    "print(\"\\nzeros(5,3):\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b28689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([5, 3])\n",
      "shape torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# check size -- both same x.shape is more pythonic, x.size is like legacy code\n",
    "print(\"size\", x.size())  \n",
    "print(\"shape\", x.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fdea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# check data type -- usually tensors are float32\n",
    "print(x.dtype)\n",
    "\n",
    "# but you can also specify while types while initializing\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# check type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c139b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# cconstruct a tensor by feeding the data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3e53c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# i.e. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81cf8f",
   "metadata": {},
   "source": [
    "# Operations with Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5acb36cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.8777, 0.8913],\n",
      "        [0.6091, 0.6113]])\n",
      "tensor([[1.8777, 1.8913],\n",
      "        [1.6091, 1.6113]])\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "x = torch.ones(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "# torch.add(x,y) #both same\n",
    "\n",
    "# in place addition, everythin with a trailing underscore is an inplace operation\n",
    "# i.e. it will modify the variable\n",
    "# y.add_(x) # more like y = x + y\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60212a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtraction\n",
    "z = x - y\n",
    "z = torch.sub(x, y)   # both same\n",
    "\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "z = torch.div(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5760c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9768, 0.2859, 0.6554],\n",
      "        [0.0844, 0.4349, 0.2885],\n",
      "        [0.7860, 0.1730, 0.4071],\n",
      "        [0.4848, 0.3739, 0.4475],\n",
      "        [0.7929, 0.4569, 0.7941]])\n",
      "x[:, 0] tensor([0.9768, 0.0844, 0.7860, 0.4848, 0.7929])\n",
      "x[1, :] tensor([0.0844, 0.4349, 0.2885])\n",
      "x[1, 1] tensor(0.4349)\n",
      "x[1,1].item() 0.4349048137664795\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
    "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
    "print(\"x[1, 1]\", x[1,1]) # element at 1, 1\n",
    "\n",
    "# .item will give the actual float value not just the tensor (va;id only if you havre one element in your tensor)\n",
    "print(\"x[1,1].item()\", x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df231736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "# if -1 it pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "p = x.view(-1,2) # see -1 can automatically detemine the necessary size\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7057c",
   "metadata": {},
   "source": [
    "# NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8ad6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "type(a): <class 'torch.Tensor'>\n",
      "\n",
      "[1. 1. 1. 1. 1.]\n",
      "type(b): <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(f\"type(a): {type(a)}\\n\")\n",
    "# torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(f\"type(b): {type(b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a264bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Careful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# -- you will see it will also modify the numpy(b) when you change a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0f33bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "\n",
      "\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.tensor(a)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(\"\\n\")\n",
    "\n",
    "# again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)  # This will change (from_numpy and to_numpy will share the same memory)\n",
    "print(c)  # this will not get modified (torch.tensor(a) will createa copy in a different location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc582a7",
   "metadata": {},
   "source": [
    "# GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bb5387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.rand(2,2).to(device)  # create tensor on cpu and move to GPU\n",
    "#x = x.to(\"cpu\")\n",
    "#x = x.to(\"cuda\")  \n",
    "\n",
    "x = torch.rand(2,2, device=device)  # or directy create them on GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
